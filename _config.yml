port: 4001
markdown: kramdown
kramdown:
  parse_block_html: true
  syntax_highlighter: rouge

exclude:
  - README.md
timezone: US/Western
papers:
  - layout: paper
    selected: y
    paper-type: inproceedings
    year: 2018
    title: "beta-BNN: A Rate-Distortion Perspective on Bayesian Neural Networks"
    authors: Shell X. Hu, Pablo G. Moreno, Andreas Damianou, Neil D. Lawrence
    doc-url: papers/nips18_bdl.pdf
    img: bbnn_log
    booktitle: NeurIPS Workshop on Bayesian Deep Learning
    abstract: > 
        We propose an alternative training framework for Bayesian neural networks (BNNs),
        which is motivated by viewing the Bayesian model for supervised learning as an autoencoder for data transmission.
        Then, a natural objective can be invoked from the rate-distortion theory.
        Specifically, we end up minimizing the mutual information between the weights and the dataset
        with a constraint that the negative log-likelihood is smaller than a certain value.
        The classical Blahut-Arimoto algorithm for solving this kind of optimization is infeasible
        due to the intractable expectations over the weights and the dataset, so
        we develop a new approximation to the steps of the Blahut-Arimoto algorithm. 
        Our method exhibits some attractive properties
        over the conventional KL-regularized training of BNNs with fixed Gaussian prior: 
        firstly, improved stability during optimization; 
        secondly, a more flexible prior which can be understood from an empirical Bayes viewpoint.
  - layout: paper
    selected: y
    paper-type: inproceedings
    year: 2018
    title: Variational Mutual Information Distillation for Transfer Learning
    authors: Sungsoo Ahn, Shell X. Hu, Andreas Damianou, Neil D. Lawrence, Zhenwen Dai 
    doc-url: papers/nips18_cl.pdf
    img: vid_log
    booktitle: NeurIPS Workshop on Continual Learning
    abstract: > 
        We consider the teacher-student framework for knowledge transfer,
        where the goal is to improve learning of a student neural network,
        given a teacher neural network pretrained on the same or a similar task.
        The majority of existing approaches for distilling knowledge from a teacher
        network to a student network rely on matching either activations or handcrafted
        features from the teacher network. Instead, in this paper we establish
        an information-theoretic framework for knowledge distillation which encourages
        high mutual information between two networks. Our framework can be applied to
        knowledge transfer between different tasks without any assumptions
        on the architectures of the teacher and the student network.
        We empirically validate our proposed framework by demonstrating its
        improvement over existing methods on various knowledge transfer tasks.
  - layout: paper
    selected: y
    paper-type: inproceedings
    year: 2018
    title: Exploring Weight Symmetry in Deep Neural Networks
    authors: Sergey Zagoruyko, Shell X. Hu, Nikos Komodakis
    doc-url: papers/symnet.pdf
    code: https://github.com/szagoruyko/symmetry.pytorch
    img: symnet_log
    booktitle: Tech. Report
    abstract: > 
        We propose to impose symmetry in neural network parameters to improve parameter usage and make use of dedicated convolution and matrix multiplication routines. Due to significant reduction in the number of parameters as a result of the symmetry constraints, one would expect a dramatic drop in accuracy. Surprisingly, we show that this is not the case, and, depending on network size, symmetry can have little or no negative effect on network accuracy, especially in deep overparameterized networks. We propose several ways to impose block symmetry in recurrent and convolutional neural networks, and show that our symmetry parameterizations satisfy universal approximation property for single hidden layer networks. We extensively evaluate these parameterizations on CIFAR, ImageNet and language modeling datasets, showing significant benefits from the use of symmetry. For instance, our ResNet-101 with channel-wise symmetry has almost 25% less parameters and only 0.2% accuracy loss on ImageNet.
  - layout: paper
    selected: y
    paper-type: inproceedings
    year: 2018
    title: SDCA-Powered Inexact Dual Augmented Lagrangian Method for Fast CRF Learning
    authors: Shell X. Hu, Guillaume Obozinski
    doc-url: papers/hu18-combined.pdf
    code: https://github.com/hushell/idal
    img: idal
    booktitle: AISTATS
    abstract: > 
      We propose an efficient dual augmented La-grangian formulation to learn conditional random fields (CRF). Our algorithm, which can be interpreted as an inexact gradient descent algorithm on the multiplier, does not require to perform global inference iteratively, and requires only a fixed number of stochastic clique-wise updates at each epoch to obtain a sufficiently good estimate of the gradient w.r.t. the Lagrange multipliers. We prove that the proposed algorithm enjoys global linear convergence for both the primal and the dual objectives. Our experiments show that the proposed algorithm outperforms state-of-the-art baselines in terms of speed of convergence.
  - layout: paper
    selected: y
    paper-type: inproceedings
    year: 2015
    title: Tree-Cut for Probabilistic Image Segmentation
    authors: Shell X. Hu, Christopher K. I. Williams, Sinisa Todorovic
    doc-url: papers/1506.03852v1.pdf
    code: https://github.com/hushell/treecut
    img: treecut
    booktitle: Arxiv
    abstract: > 
      This paper presents a new probabilistic generative model for image segmentation, i.e. the task of partitioning an image into homogeneous regions. Our model is grounded on a mid-level image representation, called a region tree, in which regions are recursively split into subregions until superpixels are reached. Given the region tree, image segmentation is formalized as sampling cuts in the tree from the model. Inference for the cuts is exact, and formulated using dynamic programming. Our tree-cut model can be tuned to sample segmentations at a particular scale of interest out of many possible multiscale image segmentations. This generalizes the common notion that there should be only one correct segmentation per image. Also, it allows moving beyond the standard single-scale evaluation, where the segmentation result for an image is averaged against the corresponding set of coarse and fine human annotations, to conduct a scale-specific evaluation. Our quantitative results are comparable to those of the leading gPb-owt-ucm method, with the notable advantage that we additionally produce a distribution over all possible tree-consistent segmentations of the image.
  - layout: paper
    paper-type: inproceedings
    selected: y
    year: 2013
    img: iccv13wa
    title: Zero-Shot Learning and Detection of Teeth in Images of Bat Skulls
    authors: Shell X. Hu, Michael Lam, Sinisa Todorovic, Thomas Dietterich, Maureen O'Leary, Andrea Cirranello, Nancy Simmons and Paul Velazco
    booktitle: ICCV Workshop on Computer Vision for Accelerated Bioscience
    doc-url: papers/iccv13wa.pdf
    venue: workshop
    code: https://github.com/AVATOL/bat
    abstract: >
      Biologists continually collect and analyze images of bat skulls for answering a variety of fundamental questions in biology. One such analysis
      involves manual annotation of the types and layout of a bat's teeth in the images. To facilitate this biological study, we have developed an
      approach to detecting and localizing the bat teeth types in unannotated images, leveraging knowledge about the teeth learned from a few
      annotated images. The key challenge is that the unlabeled images show bat skulls of ``unknown'' species, which may have different types, total 
      numbers, and layouts of the teeth from the ``known'' species appearing in the labeled images. First, we match the unlabeled images to the 
      labeled ones. This allows a transfer of  teeth annotations to the unlabeled images. Second, we learn a tree parts model on the transferred 
      annotations, and use the model for teeth detection and scoring in the unlabeled images. Our evaluation demonstrates good performance, which is 
      close to our upper bound, that of a model trained on many training examples.
  - layout: paper
    paper-type: inproceedings
    selected: y
    year: 2013
    img: iccv13wb
    title: Learning to Detect Basal Tubules of Nematocysts in SEM Images
    doc-url: papers/iccv13wb.pdf
    authors: Michael Lam, Janardhan Rao Doppa, Shell X. Hu, Sinisa Todorovic, Thomas Dietterich, Abigail Reft and Marymegan Daly
    booktitle: ICCV Workshop on Computer Vision for Accelerated Bioscience
    venue: workshop
    code: https://github.com/AVATOL/nematocyst
    abstract: >
      This paper presents a learning approach for detecting nematocysts in Scanning Electron Microscope (SEM) images. The image dataset was collected 
      and made available to us by biologists for the purposes of morphological studies of corals, jellyfish, and other species in the phylum 
      Cnidaria. Challenges for computer vision presented by this biological domain are rarely seen in general images of natural scenes. We formulate 
      nematocyst detection as labeling of a regular grid of image patches. This structured prediction problem is specified within two frameworks: CRF 
      and HC-Search. The CRF uses graph cuts for inference. The HC-Search approach is based on search in the space of outputs. It uses a learned 
      heuristic function (H) to uncover high-quality candidate labelings of image patches, and then uses a learned cost function (C) to select the 
      final prediction among the candidates. While locally optimal CRF inference may be sufficient for images of natural scenes, our results 
      demonstrate that CRF with graph cuts performs poorly on the nematocyst images, and that HC-Search outperforms CRF with graph cuts. This 
      suggests biological images of flexible objects present new challenges requiring further ad- vances of, or alternatives to existing methods.
  - layout: paper
    selected: y
    paper-type: article 
    year: 2013
    title: Toward Real-Time Pedestrian Detection Based on a Deformable Template Model
    authors: Marco Pedersoli, Jordi Gonzàlez, Shell X. Hu, Xavier Roca
    doc-url: papers/towards_real_time.pdf
    code: https://github.com/hushell/CUHOG
    img: trt
    journal: IEEE Transactions on Intelligent Transportation Systems
    volume: 15(1)
    abstract: > 
      Most advanced driving assistance systems already
      include pedestrian detection systems. Unfortunately, there is still a
      tradeoff between precision and real time. For a reliable detection,
      excellent precision–recall such a tradeoff is needed to detect as
      many pedestrians as possible while, at the same time, avoiding
      too many false alarms; in addition, a very fast computation is
      needed for fast reactions to dangerous situations. Recently, novel
      approaches based on deformable templates have been proposed
      since these show a reasonable detection performance although
      they are computationally too expensive for real-time performance.
      In this paper, we present a system for pedestrian detection based
      on a hierarchical multiresolution part-based model. The proposed
      system is able to achieve state-of-the-art detection accuracy due
      to the local deformations of the parts while exhibiting a speedup
      of more than one order of magnitude due to a fast coarse-to-fine
      inference technique. Moreover, our system explicitly infers the
      level of resolution available so that the detection of small examples
      is feasible with a very reduced computational cost. We conclude
      this contribution by presenting how a graphics processing unit-- 
      optimized implementation of our proposed system is suitable for
      real-time pedestrian detection in terms of both accuracy and speed.
  - layout: paper
    paper-type: inproceedings
    selected: y
    year: 2013
    img: icon
    title: Multi-task Bilinear Classifiers for Visual Domain Adaptation
    authors: Jiaolong Xu, Sebastian Ramos, Shell X. Hu, David Vázquez, Antonio M. López
    booktitle: "NIPS Workshop on New Directions in Transfer and Multi-Task: Learning Across Domains and Tasks"
    doc-url: papers/nipsw13.pdf
    venue: workshop
    abstract: >
      We propose a method that aims to lessen the significant accuracy degradation
      that a discriminative classifier can suffer when it is trained in a specific domain
      (source domain) and applied in a different one (target domain). The principal reason
      for this degradation is the discrepancies in the distribution of the features that
      feed the classifier in different domains. Therefore, we propose a domain adaptation
      method that maps the features from the different domains into a common subspace and 
      learns a discriminative domain-invariant classifier within it. Our algorithm combines 
      bilinear classifiers and multi-task learning for domain adaptation.
      The bilinear classifier encodes the feature transformation and classification
      parameters by a matrix decomposition. In this way, specific feature transformations
      for multiple domains and a shared classifier are jointly learned in a multi-task
      learning framework. Focusing on domain adaptation for visual object detection,
      we apply this method to the state-of-the-art deformable part-based model for cross
      domain pedestrian detection. Experimental results show that our method significantly 
      avoids the domain drift and improves the accuracy when compared to several baselines.
  - layout: paper
    paper-type: inproceedings
    selected: y
    year: 2010
    img: hug
    title: An Event Based GUI Programming Toolkit for Embedded System
    authors: Shell X. Hu, Congfeng Jiang, Wei Zhang, Jilin Zhang, Ritai Yu and Changping Lv 
    booktitle: Asia-Pacific Services Computing Conference
    doc-url: papers/hug.pdf
    abstract: >
      Due to various differences in hardware architectures of devices in ubiquitous computing systems, portability and platform-independency become the main challenge for graphics programming in system design. In this paper, we propose an adaptive user interface programming toolkit for system design in ubiquitous computing environment. The toolkit leverages an existing system software infrastructure, making the application programming straightforward and platform independent. This proposed toolkit can be divided into two parts: the first part consists of open source crossplatform graphics libraries which are encapsulated into the platform dependent part of backend library for interacting with specific system. While another one, called core library, is responsible for the functions of control logics, graphics drawing and backend management. To demonstrate the practical use of this toolkit and its portability, a case study is provided for demonstration. The test results on three different embedded systems show its good adaptability on multiplatforms.

