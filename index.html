---
layout: default
title: Shell Hu
picture: paris
news:
  - > 
      Our paper <a href="papers/nips19_ml.pdf">Empirical Bayes Meta-Learning with Synthetic Gradients</a> is accepted by <a href="http://metalearning.ml/2019/">MetaLearn 2019</a>.
  - > 
      I am a visiting scholar at KU Leuven since July 8th.
  - > 
      Attended ICML 2019 and CVPR 2019.
  - > 
      Our paper <a href="https://arxiv.org/abs/1904.05835">Variational Information Distillation for Knowledge Transfer</a> is accepted by <a href="http://cvpr2019.thecvf.com/">CVPR 2019</a>.
  - > 
      Gave a talk at STADIUS, KU Leuven, <a href="papers/mutual_info.pdf">On Variational Characterization of Mutual Information for Regularizing Deep Learning</a>, Nov 30th 2018.
  - > 
      Our paper <a href="papers/nips18_bdl.pdf">beta-BNN: A Rate-Distortion Perspective on Bayesian Neural Networks</a> is accepted by <a href="http://bayesiandeeplearning.org/">NeurIPS-BDL 2018</a>.
  - > 
      Our paper <a href="papers/nips18_cl.pdf">Variational Mutual Information Distillation for Transfer Learning</a> is accepted by <a href="https://sites.google.com/view/continual2018/">NeurIPS-CL 2018</a>.
  - >
      I am doing an internship at Amazon Cambridge supervised by Andreas Damianou and Pablo García Moreno.
  - > 
      Our paper <a href="papers/hu18-combined.pdf">SDCA-Powered Inexact Dual Augmented Lagrangian Method for Fast CRF Learning</a> accepted at AISTATS 2018.
  - > 
      Gave a poster presentation at <a href="https://obd.kaust.edu.sa/">KAUST workshop on optimization and big data</a> on fast CRF learning.
  - > 
      Attended Data Science Summer School 2017 at Ecole polytechnique.
  - > 
      I was at NIPS 2016 Barcelona. 
  - > 
      I am a volunteer of ICML 2015 at Lille.
  - >
      I am the mentor of a GSoC 2014 project for <a href="http://www.shogun-toolbox.org/">Shogun Machine Learning Toolbox</a>: <a href="http://www.shogun-toolbox.org/page/Events/gsoc2014_ideas#sosvmapprox">Structured Output Learning with Approximate Inference</a>. See our <a href="http://nbviewer.ipython.org/gist/Jiaolong/95633b7efd64bbd096f2">IPython notebook</a> by Jiaolong Xu.
  - >
      My GSoC 2013 project of general structured output models for <a href="http://www.shogun-toolbox.org/">Shogun Machine Learning Toolbox</a> is finished. A <a href="http://nbviewer.ipython.org/gist/hushell/6865729">IPython notebook</a> is available.
---
<div class="page-header">
  <div class="row">
    <div class="col-sm-3 pull-right-sm">
      <h3>Xu (Shell) Hu</h3>
      <address>
		    Coriolis B413<br/>
        École des ponts ParisTech<br/>
        6-8, Av Blaise Pascal<br/>
        Champs-sur-Marne 77455<br/>
      </address>
    </div>
  </div>
  <div class="row">
    <div class="col-sm-2 pull-right-sm">
        <a href="mailto:dom343@gmail.com"><span class="glyphicon glyphicon-envelope"></span></a> Email
    </div>
    <div class="col-sm-2">
        <a href="http://github.com/hushell">
          <img src="img/ico/github_icon.png" alt=""/>
        </a>
        Github
    </div>
  </div>
</div>

<h4>About Me</h4>
<p>
I am a PhD student at the <a href="http://imagine.enpc.fr/">IMAGINE lab</a>, École des Ponts ParisTech, supervised by <a href="http://imagine.enpc.fr/~obozinsg/">Guillaume Obozinski</a> and <a href="http://imagine.enpc.fr/~komodakn/">Nikos Komodakis</a>. 
</p>
<p>
At the beginning of my PhD, I worked on variational inference and structured output learning for probabilistic graphical models. 
In particular, I was interested in the case where the optimization problem is smooth and strongly convex. 
With these assumptions, I studied and proposed algorithms for both inference and learning with linear convergence guarantee.
I am also interested in (probabilistic) deep learning. 
My recent focuses are on the relationship between over-parameterization and generalization
and the implications from information theory.
Apart from that, combining graphical models with deep neural networks is one of my long term goals.
</p>

<h4>News</h4>
<ul>
{% for item in page.news %}
  <li>{{ item }}</li>
{% endfor %}
</ul>

